}
alc <- mutate(alc, alc_use = (Dalc + Walc) / 2)
#new variable high_use is true if alc_use > 2
alc <- mutate(alc, high_use = alc_use >2)
alc$high_use
glimpse(alc)
write.csv(alc, "~/Documents/Jaakon tutkimus/Open data kurssi s2017/GitHub/IODS-project/data/",
header=T, sep=",")
write.csv(alc, "~/Documents/Jaakon tutkimus/Open data kurssi s2017/GitHub/IODS-project/data/create_alc.csv",
header=T, sep=",")
View(alc)
#save data
write.csv(alc, "~/Documents/Jaakon tutkimus/Open data kurssi s2017/GitHub/IODS-project/data/create_alc.csv",)
#save data
write.csv(alc, "~/Documents/Jaakon tutkimus/Open data kurssi s2017/GitHub/IODS-project/data/create_alc.csv")
alc <- read.csv("create_alc.csv")
View(alc)
#save data
write.csv(alc, "~/Documents/Jaakon tutkimus/Open data kurssi s2017/GitHub/IODS-project/data/create_alc.csv", row.names=F)
alc <- read.csv("create_alc.csv")
View(alc)
write.csv(alc, "~/Documents/Jaakon tutkimus/Open data kurssi s2017/GitHub/IODS-project/data/create_alc.csv", row.names=F)
getwd()
#save data
write.csv(alc, "create_alc.csv", row.names=F)
alc <- read.csv("create_alc.csv")
View(alc)
?write.csv
alc
alc$X <- -NULL
alc$X <- NULL
#Exercise 3 Data wrangling
##Jaakko Keinaenen 20.11.2017
## Data from:
##P. Cortez and A. Silva.
##Using Data Mining to Predict Secondary School Student Performance.
##In A. Brito and J. Teixeira Eds.,
##Proceedings of 5th FUture BUsiness TEChnology Conference (FUBUTEC 2008) pp. 5-12, Porto, Portugal, April, 2008, EUROSIS, ISBN 978-9077381-39-7.
## data available in https://archive.ics.uci.edu/ml/datasets/Student+Performance
getwd()
## read the file to dataset "mat" and explore the structure and dimensions
## of the data
mat <- read.csv("~/Documents/Jaakon tutkimus/Open data kurssi s2017/GitHub/IODS-project/data/student-mat.csv", header=T,
sep=";")
str(mat); dim(mat)
## read the other file to dataset "por" and do the same
por <- read.csv("student-por.csv", header=T, sep=";")
str(por); dim(por)
#access dplyr to join the data
library(dplyr)
#choose variables used to join the data
join_by <- c("school", "sex", "age", "address", "famsize", "Pstatus",
"Medu", "Fedu", "Mjob", "Fjob", "reason", "nursery","internet")
#join the datasets by the chosen variables
mat_por <- inner_join(mat, por, by=join_by, suffix=c(".mat", ".por"))
# see the dim and str of the joined data
dim(mat_por); str(mat_por)
#combine duplicated answers in the joined data
colnames(mat_por)
# create a new data frame with only the joined columns
alc <- select(mat_por, one_of(join_by))
# the columns in the datasets which were not used for joining the data
notjoined_columns <- colnames(mat)[!colnames(mat) %in% join_by]
# print out the columns not used for joining
notjoined_columns
# if the duplicated columns are numeric, take the rounded average of the two
#if not, then use the answer from the first column
for(column_name in notjoined_columns) {
two_columns <- select(mat_por, starts_with(column_name))
first_column <- select(two_columns, 1)[[1]]
if(is.numeric(first_column)) {
alc[column_name] <- round(rowMeans(two_columns))
} else {
alc[column_name] <- first_column
}
}
#new variable alc_use is the average of weekday and weekend alcohol use
alc <- mutate(alc, alc_use = (Dalc + Walc) / 2)
#new variable high_use is true if alc_use > 2
alc <- mutate(alc, high_use = alc_use >2)
alc$high_use
#alc has 382 obs and 35 var
glimpse(alc)
#save data
write.csv(alc, "create_alc.csv", row.names=F)
alc <- read.csv("create_alc.csv")
setwd("~/Documents/Jaakon tutkimus/Open data kurssi s2017/GitHub/IODS-project")
setwd("~/Documents/Jaakon tutkimus/Open data kurssi s2017/GitHub/IODS-project/data")
alc <- read.csv("create_alc.csv")
alc <- read.csv("create_alc.csv")
View(alc)
alc <- read.csv("create_alc.csv")
setwd("~/Documents/Jaakon tutkimus/Open data kurssi s2017/GitHub/IODS-project/data")
alc <- read.csv("create_alc.csv")
colnames(alc)
summary(alc)
hist(alc$alc_use)
hist(alc$alc_use, alc$studytime)
hist(alc$studytime)
plot(studytime, alc_use)
plot(alc$studytime, alc$alc_use)
hist(alc$alc_use)
hist(alc$studytime)
plot(alc$studytime, alc$alc_use)
library(ggplot2)
library(ggplot2)
hist(alc$alc_use)
hist(alc$studytime)
plot(alc$studytime, alc$alc_use)
p<- ggplot(alc, aes(studytime, alc_use)) + geom_histogram()
p
p<- ggplot(alc, aes(studytime, alc_use)) + geom_histogram(binwidth=5)
p
library(dplyr)
p<- ggplot(alc, aes(studytime, alc_use)) + geom_histogram(binwidth=5)
p
p<- ggplot(alc, aes(studytime, alc_use)) + geom_bar(stat=identity)
View(alc)
alc$studytime
hist(alc$alc_use)
hist(alc$studytime)
g1 <- ggplot(data = alc, aes(x = alc_use)) + geom_bar()
g1
g2 <- ggplot(data = alc, aes(x = studytime)) + geom_bar()
g2
g1 + facet_wrap(sex)
View(alc)
g1 + facet_wrap(alc$sex)
g1 <- ggplot(data = alc, aes(x = alc_use)) + geom_bar(color=sex)
g1 <- ggplot(data = alc, aes(x = alc_use)) + geom_bar(color=alc$sex)
g1
g1 <- ggplot(data = alc, aes(x = alc_use)) + geom_bar(colour=alc$sex)
g1
g1 <- ggplot(data = alc, aes(x = alc_use)) + geom_bar(aes(color=sex))
g1
g1 <- ggplot(data = alc, aes(x = alc_use)) + geom_bar(aes(fill=sex))
g1 <- ggplot(data = alc, aes(x = alc_use)) + geom_bar(aes(fill=sex))
g1
g1 <- ggplot(data = alc, aes(x = alc_use)) + geom_bar(aes(fill=sex), position=dodge)
g1 <- ggplot(data = alc, aes(x = alc_use)) + geom_bar(aes(fill=sex), position="dodge")
g1
g2 <- ggplot(data = alc, aes(x = studytime)) + geom_bar()
g2
g3 <- ggplot(alc, aes(studytime, alc_use)) + geom_point()
g3
g3 <- ggplot(alc, aes(studytime, alc_use)) + geom_boxplot()
g3
g3 <- ggplot(alc, aes(studytime, alc_use)) + geom_dotplot()
g3
g3 <- ggplot(alc, aes(studytime, alc_use)) + geom_dotplot(binwidth=5)
g3
g3 <- ggplot(alc, aes(studytime, alc_use)) + geom_dotplot(binwidth=20)
g3
g3 <- ggplot(alc, aes(studytime, alc_use)) + geom_dotplot(binwidth=40)
g3
g3 <- ggplot(alc, aes(studytime, alc_use)) + geom_dotplot(binwidth=60)
g3
g3 <- ggplot(alc, aes(studytime, alc_use)) + geom_dotplot(binwidth=2)
g3
g3 <- ggplot(alc, aes(studytime, alc_use)) + geom_dotplot(binwidth=0.01)
g3
g3 <- ggplot(alc, aes(studytime, alc_use)) + geom_dotplot(binwidth=0.001)
g3
g3 <- ggplot(alc, aes(studytime, alc_use)) + geom_dotplot(binwidth=0.009)
g3
View(alc)
g3 <- ggplot(alc, aes(studytime, alc_use)) + geom_histogram(binwidth=5)
g3
g3 <- ggplot(alc, aes(studytime, alc_use)) + geom_bar()
g3
g3 <- ggplot(alc, aes(studytime, alc_use)) + geom_bar(stat=identity)
g3 <- ggplot(alc, aes(studytime, alc_use)) + geom_jitter()
g3
g3 <- ggplot(alc, aes(studytime, alc_use)) + geom_point()
g3
g3 <- ggplot(alc, aes(studytime, alc_use)) + geom_boxplot()
g3
g3 <- ggplot(alc, aes(group=studytime, alc_use)) + geom_boxplot()
g3
g3 <- ggplot(alc, aes(studytime, alc_use)) + geom_boxplot(aes(group=studytime))
g3
library(dplyr)
library(ggplot2)
g1 <- ggplot(data = alc, aes(x = alc_use)) + geom_bar(aes(fill=sex), position="dodge")
g1
g2 <- ggplot(data = alc, aes(x = studytime)) + geom_bar()
g2
g3 <- ggplot(alc, aes(studytime, alc_use)) + geom_boxplot(aes(group=studytime))
g3
table <- table(famrel, alc_use)
table <- table("famrel", "alc_use")
table
pairs(alc)
table <- table("famrel", "high_use")
table
install.packages("gmodels")
library(gmodels)
crosstable("famrel", "high_use")
library(gmodels)
crosstable("famrel", "high_use")
g1 <- ggplot(data = alc, aes(x = alc_use)) + geom_bar(aes(fill=sex), position="dodge")
g1
g2 <- ggplot(data = alc, aes(x = studytime)) + geom_bar()
g2
g3 <- ggplot(alc, aes(studytime, alc_use)) + geom_boxplot(aes(group=studytime))
g3
install.packages(tidyr)
install.packages("tidyr")
library(tidyr)
gather(alc) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") + geom_bar()
gather(alc)
m <- glm(high_use ~ age + studytime + sex + famrel, data = alc, family = "binomial")
summary(m)
OR <- coef(m) %>% exp
CI<- confint(m) %>% exp
cbind(OR, CI)
options("contrasts")
summary(alc)
str(alc)
studytime <- factor(studytime)
alc$studytime <- factor(alc$studytime)
m <- glm(high_use ~ age + studytime + sex + famrel, data = alc, family = "binomial")
summary(m)
alc$famrel <- factor(alc$famrel)
m <- glm(high_use ~ age + studytime + sex + famrel, data = alc, family = "binomial")
summary(m)
str(alc)
OR <- coef(m) %>% exp
CI<- confint(m) %>% exp
cbind(OR, CI)
m <- glm(high_use ~ age + studytime + sex + famrel -1, data = alc, family = "binomial")
summary(m)
m <- glm(high_use ~ age + studytime + sex + famrel, data = alc, family = "binomial")
summary(m)
probabilities <- predict(m, type = "response")
# add the predicted probabilities to 'alc'
alc <- mutate(alc, probability = probabilities)
# use the probabilities to make a prediction of high_use
alc <- mutate(alc, prediction = probability>0.5)
# see the last ten original classes, predicted probabilities, and class predictions
select(alc, studytime, famrel, sex, high_use, probability, prediction) %>% tail(10)
# tabulate the target variable versus the predictions
table(high_use = alc$high_use, prediction = alc$prediction)
# initialize a plot of 'high_use' versus 'probability' in 'alc'
g <- ggplot(alc, aes(x = probability, y = high_use, col=prediction))
# define the geom as points and draw the plot
g + geom_point()
# tabulate the target variable versus the predictions
table(high_use = alc$high_use, prediction = alc$prediction) %>% prop.table %>% addmargins()
probabilities <- predict(m, type = "response")
# add the predicted probabilities to 'alc'
alc <- mutate(alc, probability = probabilities)
# use the probabilities to make a prediction of high_use
alc <- mutate(alc, prediction = probability>0.5)
# see the last ten original classes, predicted probabilities, and class predictions
select(alc, studytime, famrel, sex, high_use, probability, prediction) %>% tail(10)
# tabulate the target variable versus the predictions
table(high_use = alc$high_use, prediction = alc$prediction)
# initialize a plot of 'high_use' versus 'probability' in 'alc'
g <- ggplot(alc, aes(x = probability, y = high_use, col=prediction))
# define the geom as points and draw the plot
g + geom_point()
# tabulate the target variable versus the predictions
table(high_use = alc$high_use, prediction = alc$prediction) %>% prop.table %>% addmargins()
# define a loss function (mean prediction error)
loss_func <- function(class, prob) {
n_wrong <- abs(class - prob) > 0.5
mean(n_wrong)
}
# call loss_func to compute the average number of wrong predictions in the (training) data
loss_func(class = alc$high_use, prob = alc$probability)
alc <- read.csv("create_alc.csv")
alc <- read.csv("~Users/Documents/Jaakon tutkimus/Open data kurssi s2017/GitHub/IODS-project/data/create_alc.csv")
file.choose()
alc <- read.csv("/Users/caroram/Documents/Jaakon tutkimus/Open data kurssi s2017/GitHub/IODS-project/data/create_alc.csv")
alc <- read.csv("/Users/caroram/Documents/Jaakon tutkimus/Open data kurssi s2017/GitHub/IODS-project/data/create_alc.csv")
colnames(alc)
str(alc)
library(dplyr)
library(ggplot2)
install.packages("tidyr")
library(tidyr)
g1 <- ggplot(data = alc, aes(x = alc_use)) + geom_bar(aes(fill=sex), position="dodge")
g1
g2 <- ggplot(data = alc, aes(x = studytime)) + geom_bar()
g2
g3 <- ggplot(alc, aes(studytime, alc_use)) + geom_boxplot(aes(group=studytime))
g3
alc$studytime <- factor(alc$studytime)
alc$famrel <- factor(alc$famrel)
m <- glm(high_use ~ age + studytime + sex + famrel, data = alc, family = "binomial")
summary(m)
OR <- coef(m) %>% exp
CI<- confint(m) %>% exp
cbind(OR, CI)
install.packages("tidyr")
alc <- read.csv("/Users/caroram/Documents/Jaakon tutkimus/Open data kurssi s2017/GitHub/IODS-project/data/create_alc.csv")
colnames(alc)
str(alc)
library(dplyr)
library(ggplot2)
library(tidyr)
g1 <- ggplot(data = alc, aes(x = alc_use)) + geom_bar(aes(fill=sex), position="dodge")
g1
g2 <- ggplot(data = alc, aes(x = studytime)) + geom_bar()
g2
g3 <- ggplot(alc, aes(studytime, alc_use)) + geom_boxplot(aes(group=studytime))
g3
alc$studytime <- factor(alc$studytime)
alc$famrel <- factor(alc$famrel)
m <- glm(high_use ~ age + studytime + sex + famrel, data = alc, family = "binomial")
summary(m)
OR <- coef(m) %>% exp
CI<- confint(m) %>% exp
cbind(OR, CI)
install.packages("MASS")
install.packages("MASS")
install.packages("MASS")
library(MASS)
data("Boston")
str(Boston)
dim(Boston)
pairs(Boston)
pairs(Boston)
summary(Boston)
pairs(Boston)
summary(Boston)
#correlation matrix of variables rounded in two digits
cor_matrix<-cor(Boston) %>% round(digits=2)
install.packages("corrplot")
library(corrplot)
install.packages("tidyverse")
install.packages("tidyverse")
data("Boston")
str
data("Boston")
str(Boston)
dim(Boston)
pairs(Boston)
summary(Boston)
#correlation matrix of variables rounded in two digits
cor_matrix<-cor(Boston) %>% round(digits=2)
library(dplyr)
data("Boston")
str(Boston)
dim(Boston)
pairs(Boston)
summary(Boston)
#correlation matrix of variables rounded in two digits
cor_matrix<-cor(Boston) %>% round(digits=2)
# print the correlation matrix
cor_matrix
# visualize the correlation matrix
corrplot(cor_matrix, method="circle", type = "upper", cl.pos="b", tl.pos="d", tl.cex=0.6)
hist(Boston$medv)
boston_scaled <- scale(Boston)
summary(boston_scaled)
bins <- quantile(boston_scaled$crim)
boston_scaled <- as.data.frame(boston_scaled)
# create a quantile vector of crime rate
bins <- quantile(boston_scaled$crim)
# create a categorical variable 'crime' using the quantiles as breaks
crime <- cut(boston_scaled$crim, breaks = c(bins), include.lowest = TRUE, label=c("low", "med_low", "med_high", "high"))
# remove original crim from the dataset
boston_scaled <- dplyr::select(boston_scaled, -crim)
# add the new categorical value to scaled data
boston_scaled <- data.frame(boston_scaled, crime)
# change the object to data frame
boston_scaled <- as.data.frame(boston_scaled)
# create a quantile vector of crime rate
bins <- quantile(boston_scaled$crim)
boston_scaled <- as.data.frame(boston_scaled)
bins <- quantile(boston_scaled$crim)
boston_scaled
boston_scaled <- as.data.frame(boston_scaled)
bins <- quantile(boston_scaled$crim)
summary(boston_scaled$crim)
class(boston_scaled$crim)
crime <- cut(boston_scaled$crim, breaks = c(bins), include.lowest = TRUE, label=c("low", "med_low", "med_high", "high"))
boston_scaled$crim
boston_scaled <- dplyr::select(boston_scaled, -crim)
boston_scaled <- data.frame(boston_scaled, crime)
n <- nrow(boston_scaled)
# choose randomly 80% of the rows
ind <- sample(n,  size = n * 0.8)
# create train set
train <- boston_scaled[ind,]
# create test set
test <- boston_scaled[-ind,]
# linear discriminant analysis
lda.fit <- lda(crime ~ ., data = train)
View(train)
# linear discriminant analysis
lda.fit <- lda(formula=crime ~ ., data = train)
# linear discriminant analysis
lda.fit <- lda(crime ~ ., data = train)
train[, 14:16]
colnames(train[,14:16])
colnames(train[,3])
summary(train)
boston_scaled <- as.data.frame(boston_scaled)
boston_scaled$crim
bins <- quantile(boston_scaled$crim)
crime <- cut(boston_scaled$crim, breaks = c(bins), include.lowest = TRUE, label=c("low", "med_low", "med_high", "high"))
bins
install.packages("MASS")
library(MASS)
install.packages("corrplot")
library(corrplot)
install.packages("tidyverse")
library(tidyverse)
library(dplyr)
data("Boston")
str(Boston)
dim(Boston)
pairs(Boston)
summary(Boston)
#correlation matrix of variables rounded in two digits
cor_matrix<-cor(Boston) %>% round(digits=2)
install.packages("MASS")
# create a quantile vector of crime rate
bins <- quantile(boston_scaled$crim)
# create a categorical variable 'crime' using the quantiles as breaks
crime <- cut(boston_scaled$crim, breaks = c(bins), include.lowest = TRUE, label=c("low", "med_low", "med_high", "high"))
bins
data("Boston")
str(Boston)
dim(Boston)
library(MASS)
library(corrplot)
library(tidyverse)
library(dplyr)
data("Boston")
str(Boston)
dim(Boston)
pairs(Boston)
summary(Boston)
#correlation matrix of variables rounded in two digits
cor_matrix<-cor(Boston) %>% round(digits=2)
# print the correlation matrix
cor_matrix
# visualize the correlation matrix
corrplot(cor_matrix, method="circle", type = "upper", cl.pos="b", tl.pos="d", tl.cex=0.6)
boston_scaled <- scale(Boston)
summary(boston_scaled)
boston_scaled <- as.data.frame(boston_scaled)
bins <- quantile(boston_scaled$crim)
bins
crime <- cut(boston_scaled$crim, breaks = c(bins), include.lowest = TRUE, label=c("low", "med_low", "med_high", "high"))
boston_scaled <- dplyr::select(boston_scaled, -crim)
boston_scaled <- data.frame(boston_scaled, crime)
n <- nrow(boston_scaled)
ind <- sample(n,  size = n * 0.8)
train <- boston_scaled[ind,]
test <- boston_scaled[-ind,]
lda.fit <- lda(crime ~ ., data = train)
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
classes <- as.numeric(train$crime)
# plot the lda results
plot(lda.fit, dimen = 2, col = classes, pch=classes)
lda.arrows(lda.fit, myscale = 5)
View(test)
#save crime categories from the test set
crime_cat_test <- train$crime
#save crime categories from the test set
crime_cat_test <- test$crime
#remove the categorical crime variable from the test dataset
test <- dplyr::select(test, -crime)
lda.pred <- predict(lda.fit, newdata = test)
# cross tabulate the results
table(correct = correct_classes, predicted = lda.pred$class)
lda.pred <- predict(lda.fit, newdata = test)
# cross tabulate the results
table(correct = crime_cat_test, predicted = lda.pred$class)
# cross tabulate the results
t<- table(correct = crime_cat_test, predicted = lda.pred$class)
prop.table(t)
margin.table(t)
prop.table(t, margin=0)
prop.table(t, margin=1)
prop.table(t*100, margin=1)
prop.table(t*100, margin=1)
100*prop.table(t, margin=1)
#Reload the Boston dataset and standardize the dataset
data("Boston")
summary(Boston)
boston_scaled <- scale(Boston)
dist_eu <- dist(Boston)
summary(dist_eu)
km <-kmeans(Boston, centers = 4)
# plot the Boston dataset with clusters
pairs(Boston, col = km$cluster)
#Reducing the number of pairs in the plot
pairs(Boston[6:10], col = km$cluster)
#Reducing the number of pairs in the plot
pairs(Boston[1:5], col=km$cluster)
airs(Boston[1:5], col=km$cluster)
pairs(Boston[1:5], col=km$cluster)
pairs(Boston[6:10], col = km$cluster)
km <-kmeans(Boston, centers = 4)
pairs(Boston[1:5], col = km$cluster)
pairs(Boston[6:10], col = km$cluster)
km <-kmeans(Boston, centers = 2)
pairs(Boston[1:5], col = km$cluster)
pairs(Boston[6:10], col = km$cluster)
