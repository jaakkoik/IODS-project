#Exercise 4 Clustering and classification


The dataset Boston has 506 observations and 14 variables. It is about housing values in sub-urbs of Boston and contains information about, for example, crime rate, nitrogen oxide concentrations, pupil teacher ratio in different towns.
```{r}
install.packages("MASS")
library(MASS)
install.packages("corrplot")
library(corrplot)
install.packages("tidyverse")
library(tidyverse)
library(dplyr)
data("Boston")
str(Boston)
dim(Boston)
```
```{r}
pairs(Boston)
summary(Boston)
#correlation matrix of variables rounded in two digits
cor_matrix<-cor(Boston) %>% round(digits=2)

# print the correlation matrix
cor_matrix

# visualize the correlation matrix
corrplot(cor_matrix, method="circle", type = "upper", cl.pos="b", tl.pos="d", tl.cex=0.6)
```
From the above correlation matrix: home value (medv) has a strong negative correlation with lower status of the population (lstat, red circle) and a strong positive correlation with average number of rooms per dwelling (rm, blue circle).
```{r}
hist(Boston$medv)
```
From the histogram: the distribution of housing value is right-skewed.

The scaled variables all have mean of 0.0.
```{r}
boston_scaled <- scale(Boston)
summary(boston_scaled)
```
```{r}
# change the object to data frame
boston_scaled <- as.data.frame(boston_scaled)

# create a quantile vector of crime rate
bins <- quantile(boston_scaled$crim)
bins
# create a categorical variable 'crime' using the quantiles as breaks
crime <- cut(boston_scaled$crim, breaks = c(bins), include.lowest = TRUE, label=c("low", "med_low", "med_high", "high"))
# remove original crim from the dataset
boston_scaled <- dplyr::select(boston_scaled, -crim)

# add the new categorical value to scaled data
boston_scaled <- data.frame(boston_scaled, crime)

# number of rows in the Boston dataset 
n <- nrow(boston_scaled)

# choose randomly 80% of the rows
ind <- sample(n,  size = n * 0.8)

# create train set
train <- boston_scaled[ind,]

# create test set 
test <- boston_scaled[-ind,]
```
```{r}
# linear discriminant analysis
lda.fit <- lda(crime ~ ., data = train)

# the function for lda biplot arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
  heads <- coef(x)
  arrows(x0 = 0, y0 = 0, 
         x1 = myscale * heads[,choices[1]], 
         y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
  text(myscale * heads[,choices], labels = row.names(heads), 
       cex = tex, col=color, pos=3)
}

# target classes as numeric
classes <- as.numeric(train$crime)

# plot the lda results
plot(lda.fit, dimen = 2, col = classes, pch=classes)
lda.arrows(lda.fit, myscale = 5)
```
```{r}
#save crime categories from the test set
crime_cat_test <- test$crime

#remove the categorical crime variable from the test dataset
test <- dplyr::select(test, -crime)

# predict classes with test data
lda.pred <- predict(lda.fit, newdata = test)
# cross tabulate the results
t<- table(correct = crime_cat_test, predicted = lda.pred$class)
100*prop.table(t, margin=1)
```
The model predicts correctly 52% of low cases, 63% of med_low, 58% of med_high and 100% of high cases. In every category it is better than just guessing and in high category it predicts all cases correctly.

```{r}
#Reload the Boston dataset and standardize the dataset
data("Boston")
summary(Boston)
boston_scaled <- scale(Boston)
```

